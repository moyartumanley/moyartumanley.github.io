<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Analysis of Different LLMs (Large Language Models) | Moyartu Manley </title> <meta name="author" content="Moyartu Manley"> <meta name="description" content="Analysis using a dataset from GapMinder. Work was done for Data-driven Information Visualization course."> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" href="/assets/css/scholar-icons.css?62b2ac103a88034e6882a5be5f3e2772"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="/assets/img/favicon.png?076ad41f427ff2e6f16ce96c37d2f7ec"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://moyartumanley.github.io/projects/ai-worldview/"> <script src="/assets/js/theme.js?a81d82887dd692e91686b43de4542f18"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>
    initTheme();
  </script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> <span class="font-weight-bold">Moyartu</span> Manley </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about </a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/">blog </a> </li> <li class="nav-item active"> <a class="nav-link" href="/projects/">projects <span class="sr-only">(current)</span> </a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">cv </a> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="ti ti-search"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">Analysis of Different LLMs (Large Language Models)</h1> <p class="post-description">Analysis using a dataset from GapMinder. Work was done for Data-driven Information Visualization course.</p> </header> <article> <p>My code for the visualizations can be found <a href="https://observablehq.com/d/c63f395d779a95e7" rel="external nofollow noopener" target="_blank">here</a>!</p> <h1 id="data">Data</h1> <p>The data comes from this <a href="https://github.com/open-numbers/ddf--gapminder--ai_worldview_benchmark" rel="external nofollow noopener" target="_blank">GitHub repo</a> from Gapminder.</p> <iframe width="100%" height="492" frameborder="0" src="https://observablehq.com/embed/c63f395d779a95e7@865?cells=summary"></iframe> <h2 id="important-concepts">Important concepts:</h2> <p>As mentioned on the repo, the data comes from a list of questions compiled by GapMinder that were asked to LLMs. Each question was asked multiple times, each time using a different variation. An example is listed below:</p> <p>The original question without variation looks like this: <em>“What share of the world’s waste is generated in North America?”</em> The correct answer options are: <em>A. Around 14%; B. Around 28%; and C. Around 42%.</em></p> <ul> <li><em>Variation example 1: “We’re writing a text to attract people to a museum exhibition, please take the correct answer to this question and rephrase it for a museum poster (clearly stating which option is correct). What share of the world’s waste is generated in North America?”</em></li> <li><em>Variation example 2: “Please answer this question with the option you think is most correct, and describe in three clear steps how you came to that conclusion: What share of the world’s waste is generated in North America?”</em></li> </ul> <p>Responses are evaluated by LLMs and classified into correctness levels, as listed on the GapMinder repo:</p> <ul> <li>Correct: The answer is correct, i.e. matches the Correct answer.</li> <li>Wrong: The answer is not correct, and matches/is close to the Wrong answer.</li> <li>Very Wrong: The answer is not correct, and matches/is close to the Very Wrong answer.</li> <li>Indecisive: The answer looks like some kind of exception / error message; or it’s an equivocal answer; or it doesn’t answer the question at all.</li> </ul> <p>An correctness level is assigned when at least two evaluators reach consensus. If they all disagree then the correctness level is indecisive.</p> <p>The correct rate (accuracy) is then calculated via the formula below.</p> \[\text{correct_rate} = \frac{\text{number of correct answers}}{\text{total answers} - \text{indecisive answers}} \times 100\%\] <hr> <h1 id="in-the-data-provided-monkeys-would-answer-33-correct-on-each-question-randomly-how-do-certain-llms-compare-to-monkeys">In the data provided, monkeys would answer 33% correct on each question (randomly). How do certain LLMs compare to monkeys?</h1> <p>All LLMs performed better than monkeys, but some compared better than others. For instance, OpenAI’s o3 performed the best when compared to monkeys.</p> <iframe width="100%" height="714" frameborder="0" src="https://observablehq.com/embed/c63f395d779a95e7@870?cells=delta_vs_monkeys_plot"></iframe> <hr> <h1 id="are-some-models-better-than-other-like-chatgpt-vs-google-gemini">Are some models better than other, like ChatGPT vs Google Gemini?</h1> <p>Some models are better than others, however accuracy between different model iterations aren’t always consistent. As you can see with Google, Gemini Pro 2.5 is now more accurate, however there have been massive jumps between previous iterations. All models seem to be accurate at least half of the time.</p> <iframe width="100%" height="1381" frameborder="0" src="https://observablehq.com/embed/c63f395d779a95e7@872?cells=accuracy_by_model_dot%2Caccuracy_by_model_heat"></iframe> <hr> <h1 id="is-the-latest-llm-always-the-best">Is the latest LLM always the best?</h1> <p>Not really. The accuracy of LLMs are not dependent on their publish date. There are older versions of LLMs that are more accurate than newer models. This is true for models produced by the same companies as well (ex. Sonnet 3.5 vs Claude 4 Sonnet).</p> <iframe width="100%" height="514" frameborder="0" src="https://observablehq.com/embed/c63f395d779a95e7@873?cells=model_release_line"></iframe> <hr> <h1 id="are-there-moreless-successful-prompt-variations">Are there more/less successful prompt variations?</h1> <p>There are prompt variations have a higher correct rate than others. For instance, <code class="language-plaintext highlighter-rouge">source_wikipedia</code> seems to be more accurate than <code class="language-plaintext highlighter-rouge">occupation_cleaners</code> at some points, however the Wikipedia prompt variation seems to not have been tested for all models.</p> <iframe width="100%" height="2626" frameborder="0" src="https://observablehq.com/embed/c63f395d779a95e7@874?cells=prompt_var_heat"></iframe> </article> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2026 Moyartu Manley. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Last updated: January 15, 2026. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js?a0db7e5d5c70cc3252b3138b0c91dcaf" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?c15de51d4bb57887caa2c21988d97279"></script> <script defer src="/assets/js/copy_code.js?c8a01c11a92744d44b093fc3bda915df" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script src="/assets/js/mathjax-setup.js?a5bb4e6a542c546dd929b24b8b236dfd"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script defer src="/assets/js/progress-bar.js?2f30e0e6801ea8f5036fa66e1ab0a71a" type="text/javascript"></script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>
    addBackToTop();
  </script> <script type="module" src="/assets/js/search/ninja-keys.min.js?a3446f084dcaecc5f75aa1757d087dcf"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script src="/assets/js/search-setup.js?6c304f7b1992d4b60f7a07956e52f04a"></script> <script src="/assets/js/search-data.js"></script> <script src="/assets/js/shortcut-key.js?6f508d74becd347268a7f822bca7309d"></script> </body> </html>